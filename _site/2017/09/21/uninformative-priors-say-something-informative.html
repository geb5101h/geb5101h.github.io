<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Uninformative priors say something informative about the posterior predictions | Eric Janofsky</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Uninformative priors say something informative about the posterior predictions" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This is something that has stuck with me since my Bayesian course in year two of graduate school. For a very simple example, suppose we have a set of \(n\) i.i.d. exponential data, so the likelihood takes the form \[\begin{array}{ll}p(x_1,\ldots,x_n) &amp;=&amp; \lambda^n e^{-\lambda n \bar{x}}. \end{array}\] We put an improper prior over \(\lambda\), \(p(\lambda)\propto 1 \). This basically says before we observe the data, we believe the parameter is equally likely to be any positive real number. It’s not a proper prior, but it results in a valid posterior so let’s go with it. The posterior distribution for \(\lambda\) is easily calculated as \[\begin{array}{ll}p(\lambda \mid \bar{x}) &amp;\propto&amp; \lambda^n e^{-\lambda n \bar{x}}. \end{array}\] By inspection one recognizes this as a Gamma distribution with shape parameter \(n+1\) and scale parameter \(\frac{1}{n\bar{x}}\). That means the posterior mean is \[ \mathbb{E}_{post} [\lambda] = \frac{n+1}{n} \cdot \frac{1}{\bar{x}}. \] The strange thing about this is that no matter what the sample is, the posterior always expects a value larger than the natural sample estimate (\(\frac{1}{\bar{x}}\))! A more tangible example of this problem is something called the exchange paradox. You are told to choose between two envelopes filled with money, one has twice as much as the other with unknown amounts; I get the other one. You choose one envelope and it contains $100. Then, you reason that the other envelope is equally likely to contain $50 if you’re holding the larger envelope, or $200 if you’re holding the smaller envelope. Thus, you expect to get a payoff of \(0.5 \cdot $50 + 0.5 \cdot $200 = $125\) if you trade with me. I make the same calculation with the amount in my envelope and come to the same conclusion; we both believe we will likely get a larger payoff by exchanging for the other envelope. How can this be? There’s endless discussion on this paradox, but I find it helpful to think like a Bayesian. Let’s call the quantity in the larger envelope \(X\) and the quantity you selected \(Y\); \(X\) could either take the value \(Y\) or \(2Y\) depending on whether you chose the larger or smaller amount. Now suppose you have a prior on your expectations of the value of the larger envelope, call it \(p(x)\). An application of Bayes rule gives that \[ p(X = y \mid Y=y) = \frac{p(x)}{p(x/2)+p(x)}.\] Similarly, \( p(X = 2y \mid Y=y) = \frac{p(x/2)}{p(x/2)+p(x)}\) since the likelihood of the two values must sum to one. We can now calculate the expected payout from switching: \[ E = \frac{xp(x/2) }{2p(x)+2p(x/2)} + \frac{2xp(x)}{p(x)+p(x/2)} \] Now, suppose that \(p(x)\) is the prior we considered above, uniform over the positive reals. The expected value becomes \[ E = \frac{x}{4} + x = 1.25 x\] We come to the same conclusion as the verbal argument I made above, that it is always better to switch envelopes! However, other choices of priors will yield less “paradoxical” results. For example the prior \(p(\lambda) \propto \frac{1}{\lambda} \), gives expected payoff from switching envelopes of \(x\), even odds. My take-away is that non-informative priors still have strong consequences for inference in relation to the observed data, despite having “no information”. If you use the non-informative prior for the exchange game you are saying if your envelope had $20 trillion, you have no inclination that you hold the larger envelope than if it had 20 cents. If the conclusions of the exchange paradox don’t sit right with you, it’s because you don’t really believe in the prior you chose &ndash; maybe the non-informative prior wasn’t what you really wanted." />
<meta property="og:description" content="This is something that has stuck with me since my Bayesian course in year two of graduate school. For a very simple example, suppose we have a set of \(n\) i.i.d. exponential data, so the likelihood takes the form \[\begin{array}{ll}p(x_1,\ldots,x_n) &amp;=&amp; \lambda^n e^{-\lambda n \bar{x}}. \end{array}\] We put an improper prior over \(\lambda\), \(p(\lambda)\propto 1 \). This basically says before we observe the data, we believe the parameter is equally likely to be any positive real number. It’s not a proper prior, but it results in a valid posterior so let’s go with it. The posterior distribution for \(\lambda\) is easily calculated as \[\begin{array}{ll}p(\lambda \mid \bar{x}) &amp;\propto&amp; \lambda^n e^{-\lambda n \bar{x}}. \end{array}\] By inspection one recognizes this as a Gamma distribution with shape parameter \(n+1\) and scale parameter \(\frac{1}{n\bar{x}}\). That means the posterior mean is \[ \mathbb{E}_{post} [\lambda] = \frac{n+1}{n} \cdot \frac{1}{\bar{x}}. \] The strange thing about this is that no matter what the sample is, the posterior always expects a value larger than the natural sample estimate (\(\frac{1}{\bar{x}}\))! A more tangible example of this problem is something called the exchange paradox. You are told to choose between two envelopes filled with money, one has twice as much as the other with unknown amounts; I get the other one. You choose one envelope and it contains $100. Then, you reason that the other envelope is equally likely to contain $50 if you’re holding the larger envelope, or $200 if you’re holding the smaller envelope. Thus, you expect to get a payoff of \(0.5 \cdot $50 + 0.5 \cdot $200 = $125\) if you trade with me. I make the same calculation with the amount in my envelope and come to the same conclusion; we both believe we will likely get a larger payoff by exchanging for the other envelope. How can this be? There’s endless discussion on this paradox, but I find it helpful to think like a Bayesian. Let’s call the quantity in the larger envelope \(X\) and the quantity you selected \(Y\); \(X\) could either take the value \(Y\) or \(2Y\) depending on whether you chose the larger or smaller amount. Now suppose you have a prior on your expectations of the value of the larger envelope, call it \(p(x)\). An application of Bayes rule gives that \[ p(X = y \mid Y=y) = \frac{p(x)}{p(x/2)+p(x)}.\] Similarly, \( p(X = 2y \mid Y=y) = \frac{p(x/2)}{p(x/2)+p(x)}\) since the likelihood of the two values must sum to one. We can now calculate the expected payout from switching: \[ E = \frac{xp(x/2) }{2p(x)+2p(x/2)} + \frac{2xp(x)}{p(x)+p(x/2)} \] Now, suppose that \(p(x)\) is the prior we considered above, uniform over the positive reals. The expected value becomes \[ E = \frac{x}{4} + x = 1.25 x\] We come to the same conclusion as the verbal argument I made above, that it is always better to switch envelopes! However, other choices of priors will yield less “paradoxical” results. For example the prior \(p(\lambda) \propto \frac{1}{\lambda} \), gives expected payoff from switching envelopes of \(x\), even odds. My take-away is that non-informative priors still have strong consequences for inference in relation to the observed data, despite having “no information”. If you use the non-informative prior for the exchange game you are saying if your envelope had $20 trillion, you have no inclination that you hold the larger envelope than if it had 20 cents. If the conclusions of the exchange paradox don’t sit right with you, it’s because you don’t really believe in the prior you chose &ndash; maybe the non-informative prior wasn’t what you really wanted." />
<link rel="canonical" href="http://localhost:4000/2017/09/21/uninformative-priors-say-something-informative.html" />
<meta property="og:url" content="http://localhost:4000/2017/09/21/uninformative-priors-say-something-informative.html" />
<meta property="og:site_name" content="Eric Janofsky" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-09-21T17:52:42-04:00" />
<script type="application/ld+json">
{"description":"This is something that has stuck with me since my Bayesian course in year two of graduate school. For a very simple example, suppose we have a set of \\(n\\) i.i.d. exponential data, so the likelihood takes the form \\[\\begin{array}{ll}p(x_1,\\ldots,x_n) &amp;=&amp; \\lambda^n e^{-\\lambda n \\bar{x}}. \\end{array}\\] We put an improper prior over \\(\\lambda\\), \\(p(\\lambda)\\propto 1 \\). This basically says before we observe the data, we believe the parameter is equally likely to be any positive real number. It’s not a proper prior, but it results in a valid posterior so let’s go with it. The posterior distribution for \\(\\lambda\\) is easily calculated as \\[\\begin{array}{ll}p(\\lambda \\mid \\bar{x}) &amp;\\propto&amp; \\lambda^n e^{-\\lambda n \\bar{x}}. \\end{array}\\] By inspection one recognizes this as a Gamma distribution with shape parameter \\(n+1\\) and scale parameter \\(\\frac{1}{n\\bar{x}}\\). That means the posterior mean is \\[ \\mathbb{E}_{post} [\\lambda] = \\frac{n+1}{n} \\cdot \\frac{1}{\\bar{x}}. \\] The strange thing about this is that no matter what the sample is, the posterior always expects a value larger than the natural sample estimate (\\(\\frac{1}{\\bar{x}}\\))! A more tangible example of this problem is something called the exchange paradox. You are told to choose between two envelopes filled with money, one has twice as much as the other with unknown amounts; I get the other one. You choose one envelope and it contains $100. Then, you reason that the other envelope is equally likely to contain $50 if you’re holding the larger envelope, or $200 if you’re holding the smaller envelope. Thus, you expect to get a payoff of \\(0.5 \\cdot $50 + 0.5 \\cdot $200 = $125\\) if you trade with me. I make the same calculation with the amount in my envelope and come to the same conclusion; we both believe we will likely get a larger payoff by exchanging for the other envelope. How can this be? There’s endless discussion on this paradox, but I find it helpful to think like a Bayesian. Let’s call the quantity in the larger envelope \\(X\\) and the quantity you selected \\(Y\\); \\(X\\) could either take the value \\(Y\\) or \\(2Y\\) depending on whether you chose the larger or smaller amount. Now suppose you have a prior on your expectations of the value of the larger envelope, call it \\(p(x)\\). An application of Bayes rule gives that \\[ p(X = y \\mid Y=y) = \\frac{p(x)}{p(x/2)+p(x)}.\\] Similarly, \\( p(X = 2y \\mid Y=y) = \\frac{p(x/2)}{p(x/2)+p(x)}\\) since the likelihood of the two values must sum to one. We can now calculate the expected payout from switching: \\[ E = \\frac{xp(x/2) }{2p(x)+2p(x/2)} + \\frac{2xp(x)}{p(x)+p(x/2)} \\] Now, suppose that \\(p(x)\\) is the prior we considered above, uniform over the positive reals. The expected value becomes \\[ E = \\frac{x}{4} + x = 1.25 x\\] We come to the same conclusion as the verbal argument I made above, that it is always better to switch envelopes! However, other choices of priors will yield less “paradoxical” results. For example the prior \\(p(\\lambda) \\propto \\frac{1}{\\lambda} \\), gives expected payoff from switching envelopes of \\(x\\), even odds. My take-away is that non-informative priors still have strong consequences for inference in relation to the observed data, despite having “no information”. If you use the non-informative prior for the exchange game you are saying if your envelope had $20 trillion, you have no inclination that you hold the larger envelope than if it had 20 cents. If the conclusions of the exchange paradox don’t sit right with you, it’s because you don’t really believe in the prior you chose &ndash; maybe the non-informative prior wasn’t what you really wanted.","datePublished":"2017-09-21T17:52:42-04:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017/09/21/uninformative-priors-say-something-informative.html"},"url":"http://localhost:4000/2017/09/21/uninformative-priors-say-something-informative.html","headline":"Uninformative priors say something informative about the posterior predictions","dateModified":"2017-09-21T17:52:42-04:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Eric Janofsky" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Eric Janofsky</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about.html">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>This is something that has stuck with me since my Bayesian course in year two of graduate school.</p><p>For a very simple example, suppose we have a set of \(n\) i.i.d. exponential data, so the likelihood takes the form</p><p>\[\begin{array}{ll}p(x_1,\ldots,x_n) &amp;=&amp; \lambda^n e^{-\lambda n \bar{x}}. \end{array}\] <br/></p><p>We put an improper prior over \(\lambda\), \(p(\lambda)\propto 1 \). This basically says before we observe the data, we believe the parameter is equally likely to be any positive real number. It’s not a proper prior, but it results in a valid posterior so let’s go with it.</p><p>The posterior distribution for \(\lambda\) is easily calculated as</p><p>\[\begin{array}{ll}p(\lambda \mid \bar{x}) &amp;\propto&amp; \lambda^n e^{-\lambda n \bar{x}}. \end{array}\]</p><p>By inspection one recognizes this as a Gamma distribution with shape parameter \(n+1\) and scale parameter \(\frac{1}{n\bar{x}}\). That means the posterior mean is</p><p>\[ \mathbb{E}_{post} [\lambda] = \frac{n+1}{n} \cdot \frac{1}{\bar{x}}. \]</p><p>The strange thing about this is that <i>no matter what the sample is</i>, the posterior <i>always </i>expects a value larger than the natural sample estimate (\(\frac{1}{\bar{x}}\))!</p><p>A more tangible example of this problem is something called the <i><a href="http://faculty.chicagobooth.edu/nicholas.polson/teaching/41900/exchange-1.pdf">exchange paradox</a></i>. You are told to choose between two envelopes filled with money, one has twice as much as the other with unknown amounts; I get the other one. You choose one envelope and it contains $100.</p><p>Then, you reason that the other envelope is equally likely to contain $50 if you’re holding the larger envelope, or $200 if you’re holding the smaller envelope. Thus, you expect to get a payoff of \(0.5 \cdot $50 + 0.5 \cdot $200 = $125\) if you trade with me. I make the same calculation with the amount in my envelope and come to the same conclusion; we <b>both</b> believe we will likely get a larger payoff by exchanging for the other envelope. How can this be?</p><p>There’s endless discussion on this paradox, but I find it helpful to think like a Bayesian. Let’s call the quantity in the larger envelope \(X\) and the quantity you selected \(Y\); \(X\) could either take the value \(Y\) or \(2Y\) depending on whether you chose the larger or smaller amount. Now suppose you have a prior on your expectations of the value of the larger envelope, call it \(p(x)\). An application of Bayes rule gives that</p><p>\[ p(X = y \mid Y=y) = \frac{p(x)}{p(x/2)+p(x)}.\]</p><p>Similarly, \( p(X = 2y \mid Y=y) = \frac{p(x/2)}{p(x/2)+p(x)}\) since the likelihood of the two values must sum to one. We can now calculate the expected payout from switching:</p><p>\[ E = \frac{xp(x/2) }{2p(x)+2p(x/2)} + \frac{2xp(x)}{p(x)+p(x/2)} \]</p><p>Now, suppose that \(p(x)\) is the prior we considered above, uniform over the positive reals. The expected value becomes<br/></p><p>\[ E = \frac{x}{4} + x = 1.25 x\]</p><p>We come to the same conclusion as the verbal argument I made above, that it is <i>always</i> better to switch envelopes!</p><p>However, other choices of priors will yield less “paradoxical” results. For example the prior \(p(\lambda) \propto \frac{1}{\lambda} \), gives expected payoff from switching envelopes of \(x\), even odds.</p><p>My take-away is that non-informative priors still have strong consequences for inference in relation to the observed data, despite having “no information”. If you use the non-informative prior for the exchange game you are saying if your envelope had $20 trillion, you have no inclination that you hold the larger envelope than if it had 20 cents. If the conclusions of the exchange paradox don’t sit right with you, it’s because you don’t really believe in the prior you chose &ndash; maybe the non-informative prior wasn’t what you really wanted.</p>

  </div><a class="u-url" href="/2017/09/21/uninformative-priors-say-something-informative.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Eric Janofsky</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Eric Janofsky</li><li><a class="u-email" href="mailto:ebjanofsky@gmail.com">ebjanofsky@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/geb5101h"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">geb5101h</span></a></li><li><a href="https://www.twitter.com/geb5101h"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">geb5101h</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
